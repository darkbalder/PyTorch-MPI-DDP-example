xhzhao@xhzhao-ub:~/tools/PyTorch-MPI-DDP-example/from_mingfei$ ./run.sh
[0/2] Epoch 0 Loss 0.970655 Global batch size 128 on 2 ranks
[1/2] Epoch 0 Loss 0.957377 Global batch size 128 on 2 ranks
[0/2] Epoch 1 Loss 0.409037 Global batch size 128 on 2 ranks
[1/2] Epoch 1 Loss 0.407893 Global batch size 128 on 2 ranks
[0/2] Epoch 2 Loss 0.315330 Global batch size 128 on 2 ranks
[1/2] Epoch 2 Loss 0.310589 Global batch size 128 on 2 ranks
[0/2] Epoch 3 Loss 0.269583 Global batch size 128 on 2 ranks
[1/2] Epoch 3 Loss 0.268614 Global batch size 128 on 2 ranks
[0/2] Epoch 4 Loss 0.245311 Global batch size 128 on 2 ranks
[1/2] Epoch 4 Loss 0.238192 Global batch size 128 on 2 ranks
[0/2] Epoch 5 Loss 0.223034 Global batch size 128 on 2 ranks
[1/2] Epoch 5 Loss 0.221292 Global batch size 128 on 2 ranks
[0/2] Epoch 6 Loss 0.207834 Global batch size 128 on 2 ranks
[1/2] Epoch 6 Loss 0.204415 Global batch size 128 on 2 ranks
[0/2] Epoch 7 Loss 0.199458 Global batch size 128 on 2 ranks
[1/2] Epoch 7 Loss 0.192848 Global batch size 128 on 2 ranks
[0/2] Epoch 8 Loss 0.184656 Global batch size 128 on 2 ranks
[1/2] Epoch 8 Loss 0.179757 Global batch size 128 on 2 ranks
[0/2] Epoch 9 Loss 0.177797 Global batch size 128 on 2 ranks
[1/2] Epoch 9 Loss 0.174681 Global batch size 128 on 2 ranks

